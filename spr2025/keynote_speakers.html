<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Keynote Speakers - New England NLP Symposium</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,700,700i|Raleway:300,400,500,700,800"
    rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <style>
    .keynote-card {
      margin-bottom: 30px;
      padding: 20px;
      border-radius: 8px;
      box-shadow: 0 2px 15px rgba(0, 0, 0, 0.1);
      background: #fff;
    }

    .keynote-header {
      display: flex;
      align-items: center;
      margin-bottom: 20px;
    }

    .keynote-img {
      width: 120px;
      height: 120px;
      border-radius: 50%;
      object-fit: cover;
      margin-right: 20px;
    }

    .keynote-info h3 {
      margin: 0;
      color: #333;
    }

    .keynote-info p {
      margin: 5px 0;
      color: #666;
    }

    .keynote-content {
      margin-top: 20px;
    }

    .keynote-content h4 {
      color: #333;
      margin-bottom: 10px;
    }

    .keynote-content p {
      color: #666;
      line-height: 1.6;
    }

    .talk-title {
      font-style: italic;
      color: #007bff;
      margin: 10px 0;
    }
  </style>
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="d-flex align-items-center">
    <div class="container-fluid container-xxl d-flex align-items-center">
      <div id="logo" class="me-auto">
        <a href="index.html" class="scrollto"><img src="assets/img/logo.png" alt="" title=""></a>
      </div>
      <nav id="navbar" class="navbar order-last order-lg-0">
        <ul>
          <li><a class="nav-link" href="index.html">Home</a></li>
          <li><a class="nav-link" href="index.html#about">About</a></li>
          <li><a class="nav-link" href="accepted_work.html">Accepted Work</a></li>
          <li><a class="nav-link" href="index.html#cfp">Call for Papers</a></li>
          <li><a class="nav-link" href="index.html#directions">Directions</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav>
    </div>
  </header>
  <!-- ======= Hero Section ======= -->
  <section id="hero">
    <div class="hero-container" data-aos="zoom-in" data-aos-delay="100">
      <h1 class="mb-4 pb-0" style="text-transform: none; text-align: left;">
        New England NLP Meeting Series
      </h1>
      <h2 style="color: #fff; text-align: left; font-size: 30px;">
        Keynote Speakers
      </h2>
    </div>
    </div>
  </section>
  <!-- End Hero Section -->

  <main id="main">
    <section class="inner-page">
      <div class="container">

        <!-- Yilun Du -->
        <div class="keynote-card">
          <div class="keynote-header">
            <img src="assets/img/speakers/yilun.png" alt="Yilun Du" class="keynote-img">
            <div class="keynote-info">
              <h3><a href="https://yilundu.github.io/" target="_blank">Yilun Du</a></h3>
              <p>Harvard University</p>
              <div class="talk-title">Constructing Generalizable Multimodal Models through Compositional Generation</div>
            </div>
          </div>
          <div class="keynote-content">
            <h4>Abstract</h4>
            <p>To construct intelligent embodied agents, it is important that models can ingest
            and output signals in the form of images, text, actions, and various other sensor modalities.
            However, gathering data that covers all such combinations of input data is often challenging, 
            and existing multimodal models are often frail and sensitive to distribution shift. In this talk, 
            I'll illustrate how we can circumvent some of these data challenges by instead constructing multimodal
            models compositionally -- combining models that focus on different modalities such as text,
            videos, and actions. I'll illustrate how such compositional systems enable us to construct
            zero-shot multimodal systems that can accomplish various tasks such as reasoning, vision-language
            captioning and robotic planning.</p>
            <h4>Bio</h4>
            <p>Yilun Du is an incoming assistant professor at Harvard University in the Kempner Institute
             and Computer Science. He is currently a senior research scientist at Google Deepmind and 
            previously received his PhD at MIT.</p>
          </div>
        </div>

        <!-- He He -->
        <div class="keynote-card">
          <div class="keynote-header">
            <img src="assets/img/speakers/he.png" alt="He He" class="keynote-img">
            <div class="keynote-info">
              <h3><a href="https://hhexiy.github.io/" target="_blank">He He</a></h3>
              <p>New York University</p>
              <div class="talk-title">Talk TBA</div>
            </div>
          </div>
          <div class="keynote-content">
            <h4>Abstract</h4>
            <p>Abstract coming soon.</p>
            <h4>Bio</h4>
            <p>Bio coming soon.</p>
          </div>
        </div>

        <!-- Yoon Kim -->
        <div class="keynote-card">
          <div class="keynote-header">
            <img src="assets/img/speakers/yoon.jpg" alt="Yoon Kim" class="keynote-img">
            <div class="keynote-info">
              <h3><a href="http://people.csail.mit.edu/yoonkim/" target="_blank">Yoon Kim</a></h3>
              <p>MIT</p>
              <div class="talk-title">On the Future of Transformers</div>
            </div>
          </div>
          <div class="keynote-content">
            <h4>Abstract</h4>
            <p>Transformers are still the dominant architecture for language modeling (and generative AI more broadly). This talk will speculate on how Transformers (in particular the attention mechanism) will change over the near future.</p>
            <h4>Bio</h4>
            <p>Yoon Kim is an assistant professor at MIT. He obtained his PhD from Harvard University.</p>
          </div>
        </div>

        <!-- Alex Lew -->
        <div class="keynote-card">
          <div class="keynote-header">
            <img src="assets/img/speakers/alex.png" alt="Alex Lew" class="keynote-img">
            <div class="keynote-info">
              <h3><a href="https://alexlew.net/" target="_blank">Alex Lew</a></h3>
              <p>Yale University</p>
              <div class="talk-title">Language Model Probabilistic Programming</div>
            </div>
          </div>
          <div class="keynote-content">
            <h4>Abstract</h4>
            <p>Even after fine-tuning and reinforcement learning, language models can be difficult to control reliably with prompts alone. This talk proposes a new approach to specifying and executing tasks using language models, based on probabilistic programming. Language model probabilistic programs precisely and compositionally specify target distributions from which to generate samples. These distributions generally arise by applying hard and soft constraints to the default output distributions of one or more LMs. Samples can then be drawn approximately from these target distributions using sequential Monte Carlo â€” and their quality improved via test-time scaling of the number of particles used by the algorithm. This talk will demonstrate that language model probabilistic programs can improve downstream performance on a broad variety of tasks, from Python code generation to molecule synthesis to trip planning. It will also show how language models can themselves write language model probabilistic programs, enabling small LMs can outperform frontier models on a number of challenging tasks.</p>
            <h4>Bio</h4>
            <p>Alex Lew is an incoming Assistant Professor of Computer Science at Yale. His research focuses on the intersection of programming languages and probabilistic machine learning, aiming to develop systems and theory that facilitate the invention, application, and understanding of scalable algorithms for probabilistic modeling and inference. Alex attended graduate school under the supervision of Vikash Mansinghka and Joshua Tenenbaum. Prior to his PhD, Alex taught computer science to high school students at the Commonwealth School in Boston, MA. Alex's work has been recognized with a 2019 Facebook Probability and Programming Award, a 2020 NSF Graduate Research Fellowship, and 2023 ACM SIGPLAN and ACM SIGLOG Distinguished Paper awards.</p>
          </div>
        </div>

        <!-- Byron Wallace -->
        <div class="keynote-card">
          <div class="keynote-header">
            <img src="assets/img/speakers/bryon.png" alt="Byron Wallace" class="keynote-img">
            <div class="keynote-info">
              <h3><a href="https://byronwallace.com/" target="_blank">Byron Wallace</a></h3>
              <p>Northeastern University</p>
              <div class="talk-title">LLMs for healthcare: Risks and interpretability methods to (possibly) mitigate them</div>
            </div>
          </div>
          <div class="keynote-content">
            <h4>Abstract</h4>
            <p>Abstract coming soon.</p>
            <h4>Bio</h4>
            <p>Bio coming soon.</p>
          </div>
        </div>

        <!-- Jason Weston -->
        <div class="keynote-card">
          <div class="keynote-header">
            <img src="assets/img/speakers/jason.jpg" alt="Jason Weston" class="keynote-img">
            <div class="keynote-info">
              <h3><a href="https://ai.meta.com/people/1163645124801199/jason-weston/" target="_blank">Jason Weston</a></h3>
              <p>Meta / New York University</p>
              <div class="talk-title">Self-Improvement of LLMs</div>
            </div>
          </div>
          <div class="keynote-content">
            <h4>Abstract</h4>
            <p>We describe recent methods that enable large language models (LLMs) to self-improve, increasing their performance on tasks relevant to human users. In particular we describe the methods of Self-Rewarding LLMs (https://arxiv.org/abs/2401.10020), Iterative Reasoning Preference Optimization (https://arxiv.org/abs/2404.19733), Thinking LLMs (https://arxiv.org/abs/2410.10630), Meta-Rewarding LLMs (https://arxiv.org/abs/2407.19594), and more!</p>
            <h4>Bio</h4>
            <p>Jason Weston is a research scientist at Meta AI, USA and a Visiting Research Professor at NYU. He earned his PhD in machine learning at Royal Holloway, University of London and at AT&T Research in Red Bank, NJ (advisors: Alex Gammerman, Volodya Vovk and Vladimir Vapnik) in 2000. From 2000 to 2001, he was a researcher at Biowulf technologies. From 2002 to 2003 he was a research scientist at the Max Planck Institute for Biological Cybernetics, Tuebingen, Germany. From 2003 to 2009 he was a research staff member at NEC Labs America, Princeton. From 2009 to 2014 he was a research scientist at Google, NY. Jason's publications include best paper awards at ICML and ECML, and a Test of Time Award for his work "A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning", ICML 2008 (with Ronan Collobert). He was part of the YouTube team that won a National Academy of Television Arts & Sciences Emmy Award for Technology and Engineering for Personalized Recommendation Engines for Video Discovery. Some of his notable work influencing the field of NLP includes the "NLP from scratch" work starting in 2008 which introduced pretraining and fine-tuning of language models, Memory Networks in 2014-2015 which introduced multi-layer attention pre-Transformers, DrQA in 2017 which introduced RAG-like methods, BlenderBot 1-3 and other LLM dialogue research pre-chatGPT in 2018-2022, and more recently work like Self-Rewarding LLMs for self-improvement.</p>
          </div>
        </div>

      </div>
    </section>
  </main>

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">
      <div class="copyright">
      </div>
      <div class="credits">
        Template adopted from <a href="https://set-llm.github.io/">SeT LLM @ ICLR 2024</a>
      </div>
    </div>
  </footer>

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i
      class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html> 